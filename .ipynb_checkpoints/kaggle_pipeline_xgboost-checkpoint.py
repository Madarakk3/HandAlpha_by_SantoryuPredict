
# ğŸ“¦ Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.metrics import accuracy_score
import xgboost as xgb

# ğŸ“¥ Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ°
df = pd.read_csv("train.csv")
df_test = pd.read_csv("test.csv")
submission = pd.read_csv("sample_submission.csv")

# ğŸ¯ Ğ¦ĞµĞ»ĞµĞ²Ğ°Ñ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ğ°Ñ
df["Transported"] = df["Transported"].astype(int)

# ğŸ§  Feature Engineering
def enrich(df):
    df[["Deck", "Num", "Side"]] = df["Cabin"].str.split("/", expand=True)
    df["Group"] = df["PassengerId"].apply(lambda x: x.split("_")[0])
    df["NameLength"] = df["Name"].fillna("").apply(len)
    df["TotalSpend"] = df[["RoomService", "FoodCourt", "ShoppingMall", "Spa", "VRDeck"]].fillna(0).sum(axis=1)
    df["IsZeroSpend"] = (df["TotalSpend"] == 0).astype(int)
    df["CryoZero"] = ((df["CryoSleep"] == True) & (df["TotalSpend"] == 0)).astype(int)
    return df

df = enrich(df)
df_test = enrich(df_test)

# ğŸ“¤ X / y
drop_cols = ["Transported", "PassengerId", "Name", "Cabin"]
X = df.drop(columns=drop_cols)
y = df["Transported"]

# ĞšĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¸ Ñ‡Ğ¸ÑĞ»Ğ¾Ğ²Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¸
cat_features = X.select_dtypes(include="object").columns.tolist()
num_features = X.select_dtypes(include=["int64", "float64", "bool"]).columns.tolist()

# ğŸ”§ ĞŸÑ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ
preprocessor = ColumnTransformer(transformers=[
    ("num", Pipeline([
        ("imputer", SimpleImputer(strategy="mean")),
        ("scaler", StandardScaler())
    ]), num_features),

    ("cat", Pipeline([
        ("imputer", SimpleImputer(strategy="most_frequent")),
        ("encoder", OneHotEncoder(handle_unknown="ignore", sparse_output=False))
    ]), cat_features)
])

# ğŸŒŸ XGBoost Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ
model = Pipeline(steps=[
    ("preprocessor", preprocessor),
    ("classifier", xgb.XGBClassifier(n_estimators=300, max_depth=6, learning_rate=0.05, use_label_encoder=False, eval_metric="logloss", random_state=42))
])

# âœ‚ï¸ Train/Test Split
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)

# ğŸ‹ ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ
model.fit(X_train, y_train)

# ğŸ§ª ĞÑ†ĞµĞ½ĞºĞ°
y_pred = model.predict(X_valid)
acc = accuracy_score(y_valid, y_pred)
print(f"Validation accuracy (XGBoost): {acc:.4f}")

# ğŸ”® ĞŸÑ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğµ
X_test = df_test.drop(columns=["PassengerId", "Name", "Cabin"])
predictions = model.predict(X_test)

# ğŸ“ Submission
submission["Transported"] = predictions.astype(bool)
submission.to_csv("submission_xgboost.csv", index=False)
print("âœ… submission_xgboost.csv Ğ³Ğ¾Ñ‚Ğ¾Ğ²!")
